# Co-LLIETrack: Co-trained Low Light Image Enhancement-Tracker for UAV Tracking

<p align="center">
  <img src="titlepic.png" alt="Architecture" width="700">
</p>

## ğŸ” Abstract

Tracking unmanned aerial vehicles (UAVs) in **low-light conditions** is challenging due to poor visibility, noise, and lack of suitable datasets. Existing LLIE-Tracker frameworks primarily target **UAV-to-ground** tracking. In contrast, this work extends the framework to **ground-to-UAV** tracking and proposes:

- A **co-training strategy** using a novel loss function â€” **Semantic Feature Map with IOU Matching (SFMIOU) loss** â€” to jointly train the image enhancer and tracker.
- A **synthetic dataset**, **DeepLowLight-UAV**, generated using a DL-based day-to-night pipeline for training in diverse low-light scenarios.

**Comprehensive experiments** on the Anti-UAV-I benchmark show up to **4â€“6% improvements** in accuracy and real-time feasibility (>30 FPS).

---

## ğŸ—ï¸ Framework Overview

### ğŸ“· LLIE-Tracker System Architecture

The system supports **UAV-to-Ground** and **Ground-to-UAV** tracking using co-training of the LLIE module and Tracker.

<p align="center">
  <img src="image.png" alt="System Overview" width="700">
</p>

### ğŸš€ Performance Analysis (FPS)

<p align="center">
  <img src="fps_performace.png" alt="Performance Chart" width="700">
</p>

---

## ğŸ“¦ Project Structure

```
Co-LLIETrack/
â”‚
â”œâ”€â”€ dataset/                     # Dataset scripts and instructions
â”‚   â”œâ”€â”€ DeepLowLight-UAV/       # Synthetic low-light dataset (optional download)
â”‚
â”œâ”€â”€ models/                     # LLIE and Tracker models
â”‚   â”œâ”€â”€ HighLightNet/
â”‚   â”œâ”€â”€ DarkLighter/
â”‚   â””â”€â”€ SCT/
â”‚
â”œâ”€â”€ training/                   # Co-training pipeline code
â”‚   â””â”€â”€ sfmiou_loss.py
â”‚
â”œâ”€â”€ inference/                  # Test scripts
â”‚   â””â”€â”€ run_tracker.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ LLIETracker/  
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Getting Started

### ğŸ”§ Installation

```bash
git clone https://github.com/yourusername/Co-LLIETrack.git
cd Co-LLIETrack
pip install -r requirements.txt
```

### ğŸ“ Dataset Preparation

1. **Download Anti-UAV-I dataset**: [Anti-UAV Benchmark](https://anti-uav.github.io/leaderboard/)
2. **Generate Synthetic Data** using `dataset/deeplowlight_generator.py` (based on TSIT and BSRGAN)
3. Place data in `dataset/DeepLowLight-UAV/`

---

## ğŸƒâ€â™‚ï¸ Training

```bash
python training/train_sfmiou.py --config configs/highlightnet_mixformer.yaml
```

This performs **2-stage training**:
- Stage 1: Pretrain tracker on daytime UAV images
- Stage 2: Co-train LLIE + tracker on synthetic low-light data with **SFMIOU loss**

---

## ğŸ§  Evaluation

```bash
python inference/run_tracker.py --dataset anti-uav-i --tracker MixFormer --llie HighLightNet
```

Outputs tracking predictions, performance metrics (precision/IoU), and FPS.

---

## ğŸ“Š Key Results

### âœ… Co-Training Performance Gains

| LLIE Method   | Tracker       | Separate | Co-Trained | Gain (%) |
|---------------|---------------|----------|------------|----------|
| HighLightNet  | SiamAPN++     | 0.591    | 0.607      | +2.7     |
| SCT           | ATOM          | 0.641    | 0.677      | +5.6     |
| DarkLighter   | SuperDiMP     | 0.778    | 0.795      | +2.1     |
| UDAT          | ODTrack       | 0.648    | 0.674      | +4.0     |

> See full results in the paper (Table IVâ€“VI) and figures 9â€“14 for attribute-based and qualitative evaluations.

---

## ğŸ—‚ Dataset: DeepLowLight-UAV

| Metric          | Value     |
|-----------------|-----------|
| Sequences       | 55        |
| Frames          | 74,025    |
| Source          | Day-to-Night via TSIT + BSRGAN |
| Annotations     | Bounding Boxes (from day images) |
| Augmentation    | Blur, Noise, Contrast Variations |

---

## ğŸ“Œ Highlights

- âš¡ **Real-Time**: Avg FPS >30 (ATOM: 36.3 FPS)
- ğŸ“ˆ **Improved LLIE Quality**: Co-training improves PSNR of enhancement outputs by up to 7.4%
- ğŸ¯ **Generalizable**: Works well even when trained only on synthetic data

---

## ğŸ“„ Citation

If you find this work helpful, please cite:

```bibtex
@article{CoLLIETrack2025,
  title     = {Co-LLIETrack: Co-trained Low Light Image Enhancement-Tracker for UAV Tracking},
  author    = {Tushar Sangam and collaborators},
  journal   = {IEEE Journal of LaTeX Class Files},
  year      = {2025},
  note      = {arXiv preprint arXiv:XXXX.XXXXX}
}
```

---

## ğŸ¤ Acknowledgements

- [Anti-UAV Benchmark](https://anti-uav.github.io/leaderboard/)
- TSIT, BSRGAN, HighLightNet, Mixformer authors
- Dataset annotation support via `LabelImg`

---

## ğŸ“¬ Contact

For questions or contributions, please open an issue or reach out at:
**email@example.com**
